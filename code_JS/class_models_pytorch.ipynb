{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"class_models_pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1p3z7swbfz2Tx3VZVK7kt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Imports\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset, random_split"],"metadata":{"id":"MsD62SzXlvyi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Funciones para runnear los modelos"],"metadata":{"id":"e83SutewmN1Z"}},{"cell_type":"code","source":["def evaluate(model, val_loader):\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def do_training(model, train_loader, optimizer):\n","    outputs = [model.training_step(batch, optimizer) for batch in train_loader]\n","    return model.training_epoch_end(outputs)\n","\n","def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD, weights=''):\n","    history = []\n","    optimizer = opt_func(model.parameters(), lr)\n","    for epoch in range(epochs):\n","        # Training Phase \n","        train_epoch_end = do_training(model, train_loader, optimizer)\n","        # Validation phase\n","        val_epoch_end = evaluate(model, val_loader)\n","        model.epoch_end(epoch, train_epoch_end, val_epoch_end)\n","        history.append(val_epoch_end)\n","    return history"],"metadata":{"id":"dpsPhKphmJnH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear with gene expression\n","-----------------------"],"metadata":{"id":"p9c9O3L78t7W"}},{"cell_type":"code","source":["class DeepSF(nn.Module):\n","    def __init__(self, n_inputs, n_outputs):\n","        super().__init__()\n","        # Create the weights para la expresión de los genes de las isoformas:\n","        self.weights_gn = torch.nn.Parameter(torch.randn(n_outputs, requires_grad=True))\n","        self.linear = nn.Linear(n_inputs, n_outputs)\n","              \n","    def forward(self, xb, gb):\n","        krn = torch.kron(torch.ones((xb.shape[0],1)), self.weights_gn) #batch size es de 32 y último 20.\n","        out = self.linear(xb) + krn * gb \n","        return out\n","\n","    def training_step(self, batch, optimizer):\n","        inputs, targets, gen_expr = batch \n","\n","        out = self(inputs, gen_expr) # Generate predictions\n","        loss = F.mse_loss(out, targets)   # Calculate loss\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        return {'loss': loss.detach()}\n","\n","    def validation_step(self, batch):\n","        inputs, targets, gb = batch \n","        out = self(inputs, gb)                # Generate predictions\n","        loss_val = F.mse_loss(out, targets)       # Calculate loss\n","\n","        return {'val_loss': loss_val.detach()}\n","\n","    def training_epoch_end(self, outputs):\n","        batch_losses = [x['loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        return {'loss': epoch_loss.item()}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        return {'val_loss': epoch_loss.item()}\n","    \n","    def epoch_end(self, epoch, loss, result):\n","        print(\"Epoch [{}], loss: {:.4f}, val_loss: {:.4f}\".format(epoch, loss['loss'], result['val_loss']))"],"metadata":{"id":"x1_3QYJK8oaC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2 hidden layers with gene expression"],"metadata":{"id":"3oqccq2va94N"}},{"cell_type":"code","source":["class DeepSF_2hidden(nn.Module):\n","    def __init__(self, n_inputs, n_outputs):\n","        super().__init__()\n","        self.weights_gn = torch.nn.Parameter(torch.randn(n_outputs, requires_grad=True))\n","        self.linear1 = nn.Linear(n_inputs, 183)\n","        self.linear2 = nn.Linear(183, 82)\n","        self.linear3 = nn.Linear(82, n_outputs)\n","        \n","    def forward(self, input, gb):\n","        krn = torch.kron(torch.ones((input.shape[0],1)), self.weights_gn) #batch size es de 32 y último 20.\n","        x = F.relu(self.linear1(input))\n","        x = F.relu(self.linear2(x))\n","        out = F.relu(self.linear3(x) + krn * gb)\n","        return out\n","\n","    def training_step(self, batch, optimizer):\n","        inputs, targets, gen_expr = batch \n","        out = self(inputs, gen_expr)   # Generate predictions\n","        loss = F.mse_loss(out, targets)    # Calculate loss\n","\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        return {'loss': loss.detach()}\n","    \n","    def validation_step(self, batch):\n","        inputs, targets, gb = batch \n","        out = self(inputs, gb)             # Generate predictions\n","        loss_val = F.mse_loss(out, targets)    # Calculate loss\n","        return {'val_loss': loss_val.detach()}\n","\n","    def training_epoch_end(self, outputs):\n","        batch_losses = [x['loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        return {'loss': epoch_loss.item()}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        return {'val_loss': epoch_loss.item()}\n","    \n","    def epoch_end(self, epoch, loss, result):\n","        print(\"Epoch [{}], loss: {:.4f}, val_loss: {:.4f}\".format(epoch, loss['loss'], result['val_loss']))"],"metadata":{"id":"q2sZ56Iy8imb","executionInfo":{"status":"ok","timestamp":1647562088101,"user_tz":-60,"elapsed":346,"user":{"displayName":"Joseba Sancho Zamora","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11939503353668103171"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## 2 hidden layers weighted "],"metadata":{"id":"h_fEk2F7vcUg"}},{"cell_type":"code","source":["#def f_rmse(out, real):\n","#  return torch.sum((out-real)**2)/out.nelement()\n","\n","def f_rmse_weighted(input, target, weights):\n","    return torch.sum(weights * (input - target) ** 2)/input.nelement()"],"metadata":{"id":"h1dYtrbEvfQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DeepSFHiddenWeighted(nn.Module):\n","    def __init__(self, n_inputs, n_outputs, weights=''):\n","        super().__init__()\n","\n","        if len(weights)>0:\n","          self.weights = weights\n","\n","        self.weights_gn = torch.randn(n_outputs, requires_grad=True)\n","        self.linear1 = nn.Linear(n_inputs, 183) # 1279\n","        self.linear2 = nn.Linear(183, 82)\n","        self.linear3 = nn.Linear(82, n_outputs) # 162429\n","        \n","    def forward(self, input, gb):\n","        krn = torch.kron(torch.ones((input.shape[0],1)), self.weights_gn) #batch size es de 32 y último 20.\n","        x = F.relu(self.linear1(input))\n","        x = F.relu(self.linear2(x))\n","        out = F.relu(self.linear3(x) + krn * gb)\n","        return out\n","\n","    def training_step(self, batch, optimizer, lr):\n","        inputs, targets, gen_expr = batch \n","        out = self(inputs, gen_expr)    # Generate predictions\n","        if len(weights)>0:\n","          loss = f_rmse_weighted(out, targets, self.weights) #F.mse_loss(out, targets)    # Calculate loss\n","        else:\n","          loss = F.mse_loss(out, targets)    # Calculate loss\n","        \n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        with torch.no_grad():\n","          self.weights_gn -=  self.weights_gn.grad * lr\n","          self.weights_gn.grad.zero_()\n","\n","        return {'loss': loss.detach()}\n","      \n","    def validation_step(self, batch):\n","        inputs, targets, gb = batch \n","        out = self(inputs, gb)                 # Generate predictions\n","        if len(weights)>0:\n","          loss = f_rmse_weighted(out, targets, self.weights) #F.mse_loss(out, targets)    # Calculate loss\n","        else:\n","          loss = F.mse_loss(out, targets)    # Calculate loss        \n","        return {'val_loss': loss.detach()}\n","\n","    def training_epoch_end(self, outputs):\n","        batch_losses = [x['loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        return {'loss': epoch_loss.item()}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        return {'val_loss': epoch_loss.item()}\n","    \n","    def epoch_end(self, epoch, loss, result):\n","        print(\"Epoch [{}], loss: {:.4f}, val_loss: {:.4f}\".format(epoch, loss['loss'], result['val_loss']))\n","  "],"metadata":{"id":"8JUO75sfv7Pm"},"execution_count":null,"outputs":[]}]}